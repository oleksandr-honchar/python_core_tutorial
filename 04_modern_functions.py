"""
–ú–æ–¥—É–ª—å 2.2: –°—É—á–∞—Å–Ω—ñ —Ñ—É–Ω–∫—Ü—ñ—ó —Ç–∞ –ø–∞—Ç–µ—Ä–Ω–∏ –¥–ª—è DS/DE
=================================================

Advanced function patterns –¥–ª—è Data Science/Engineering
Python 3.10+ features
"""

from functools import wraps, lru_cache, partial
from time import time, sleep
from typing import Callable, Any
from dataclasses import dataclass
import statistics

# ============================================================================
# 1. –î–ï–ö–û–†–ê–¢–û–†–ò - TIMING –î–õ–Ø DATA PIPELINES
# ============================================================================

print("=" * 70)
print("1. –î–ï–ö–û–†–ê–¢–û–†–ò - –í–ò–ú–Ü–†–Æ–í–ê–ù–ù–Ø –ß–ê–°–£ –í–ò–ö–û–ù–ê–ù–ù–Ø")
print("=" * 70)

def timing_decorator(func: Callable) -> Callable:
    """
    –î–µ–∫–æ—Ä–∞—Ç–æ—Ä –¥–ª—è –≤–∏–º—ñ—Ä—é–≤–∞–Ω–Ω—è —á–∞—Å—É –≤–∏–∫–æ–Ω–∞–Ω–Ω—è —Ñ—É–Ω–∫—Ü—ñ—ó
    –ö—Ä–∏—Ç–∏—á–Ω–æ –≤–∞–∂–ª–∏–≤–æ –¥–ª—è ML pipelines —Ç–∞ ETL
    """
    @wraps(func)
    def wrapper(*args, **kwargs):
        start_time = time()
        result = func(*args, **kwargs)
        end_time = time()
        
        execution_time = end_time - start_time
        print(f"‚è±Ô∏è  {func.__name__} –≤–∏–∫–æ–Ω–∞–Ω–æ –∑–∞ {execution_time:.4f}s")
        
        return result
    return wrapper


@timing_decorator
def process_large_dataset(n: int) -> int:
    """–°–∏–º—É–ª—è—Ü—ñ—è –æ–±—Ä–æ–±–∫–∏ –≤–µ–ª–∏–∫–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç—É"""
    sleep(0.1)  # –°–∏–º—É–ª—é—î–º–æ –æ–±—Ä–æ–±–∫—É
    return sum(range(n))


# –¢–µ—Å—Ç
result = process_large_dataset(1_000_000)
print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result:,}")


# ============================================================================
# 2. –î–ï–ö–û–†–ê–¢–û–† –î–õ–Ø –õ–û–ì–£–í–ê–ù–ù–Ø
# ============================================================================

print("\n" + "=" * 70)
print("2. –î–ï–ö–û–†–ê–¢–û–† –î–õ–Ø –õ–û–ì–£–í–ê–ù–ù–Ø –í–ò–ö–õ–ò–ö–Ü–í")
print("=" * 70)

def log_calls(func: Callable) -> Callable:
    """
    –õ–æ–≥—É—î –≤–∏–∫–ª–∏–∫–∏ —Ñ—É–Ω–∫—Ü—ñ–π –∑ –∞—Ä–≥—É–º–µ–Ω—Ç–∞–º–∏
    –ö–æ—Ä–∏—Å–Ω–æ –¥–ª—è debugging ML pipelines
    """
    @wraps(func)
    def wrapper(*args, **kwargs):
        args_repr = [repr(a) for a in args]
        kwargs_repr = [f"{k}={v!r}" for k, v in kwargs.items()]
        signature = ", ".join(args_repr + kwargs_repr)
        
        print(f"üìû –í–∏–∫–ª–∏–∫ {func.__name__}({signature})")
        result = func(*args, **kwargs)
        print(f"‚úÖ {func.__name__} –ø–æ–≤–µ—Ä–Ω—É–≤ {result!r}")
        
        return result
    return wrapper


@log_calls
def calculate_average(numbers: list[float]) -> float:
    """–û–±—á–∏—Å–ª—é—î —Å–µ—Ä–µ–¥–Ω—î –∑–Ω–∞—á–µ–Ω–Ω—è"""
    return sum(numbers) / len(numbers) if numbers else 0.0


# –¢–µ—Å—Ç
avg = calculate_average([10, 20, 30, 40, 50])


# ============================================================================
# 3. CACHING/MEMOIZATION - –û–ü–¢–ò–ú–Ü–ó–ê–¶–Ü–Ø
# ============================================================================

print("\n" + "=" * 70)
print("3. LRU CACHE - –û–ü–¢–ò–ú–Ü–ó–ê–¶–Ü–Ø –î–û–†–û–ì–ò–• –û–ë–ß–ò–°–õ–ï–ù–¨")
print("=" * 70)

@lru_cache(maxsize=128)
def expensive_calculation(n: int) -> int:
    """
    –î–æ—Ä–æ–≥–∞ –æ–ø–µ—Ä–∞—Ü—ñ—è –∑ –∫–µ—à—É–≤–∞–Ω–Ω—è–º
    
    lru_cache –∫–µ—à—É—î —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ - –∫—Ä–∏—Ç–∏—á–Ω–æ –¥–ª—è:
    - Feature engineering
    - –ü–æ–≤—Ç–æ—Ä—é–≤–∞–Ω—ñ –æ–±—á–∏—Å–ª–µ–Ω–Ω—è –≤ ML
    - API calls
    """
    print(f"  üîÑ –û–±—á–∏—Å–ª—é—é –¥–ª—è {n}... (—Ü–µ –¥–æ—Ä–æ–≥–æ!)")
    sleep(0.1)  # –°–∏–º—É–ª—è—Ü—ñ—è –≤–∞–∂–∫–æ—ó –æ–ø–µ—Ä–∞—Ü—ñ—ó
    return n ** 2 + n * 10


# –ü–µ—Ä—à–∏–π –≤–∏–∫–ª–∏–∫ - –æ–±—á–∏—Å–ª–µ–Ω–Ω—è
print("–ü–µ—Ä—à–∏–π –≤–∏–∫–ª–∏–∫:")
result1 = expensive_calculation(100)
print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result1}")

# –î—Ä—É–≥–∏–π –≤–∏–∫–ª–∏–∫ - –∑ –∫–µ—à—É!
print("\n–î—Ä—É–≥–∏–π –≤–∏–∫–ª–∏–∫ (–∑ –∫–µ—à—É):")
result2 = expensive_calculation(100)
print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result2}")

# –Ü–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –ø—Ä–æ –∫–µ—à
print(f"\n–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫–µ—à—É: {expensive_calculation.cache_info()}")


# ============================================================================
# 4. –ì–ï–ù–ï–†–ê–¢–û–†–ò - –î–õ–Ø –í–ï–õ–ò–ö–ò–• –î–ê–¢–ê–°–ï–¢–Ü–í
# ============================================================================

print("\n" + "=" * 70)
print("4. –ì–ï–ù–ï–†–ê–¢–û–†–ò - –†–û–ë–û–¢–ê –ó –í–ï–õ–ò–ö–ò–ú–ò –î–ê–ù–ò–ú–ò")
print("=" * 70)

def read_large_file_bad(n: int) -> list[int]:
    """
    –ü–û–ì–ê–ù–ò–ô —Å–ø–æ—Å—ñ–± - –∑–∞–≤–∞–Ω—Ç–∞–∂—É—î –≤—Å–µ –≤ –ø–∞–º'—è—Ç—å
    ‚ùå –ù–µ –ø—ñ–¥—Ö–æ–¥–∏—Ç—å –¥–ª—è –≤–µ–ª–∏–∫–∏—Ö —Ñ–∞–π–ª—ñ–≤
    """
    return [i for i in range(n)]


def read_large_file_good(n: int):
    """
    –î–û–ë–†–ò–ô —Å–ø–æ—Å—ñ–± - –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä
    ‚úÖ –û–±—Ä–æ–±–ª—è—î –ø–æ –æ–¥–Ω–æ–º—É –µ–ª–µ–º–µ–Ω—Ç—É
    ‚úÖ –ù–µ –∑–∞–π–º–∞—î –≤—Å—é –ø–∞–º'—è—Ç—å
    """
    for i in range(n):
        yield i


# –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è
print("–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä vs —Å–ø–∏—Å–æ–∫:")
large_n = 1_000_000

# –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä - —Å—Ç–≤–æ—Ä—é—î—Ç—å—Å—è –º–∏—Ç—Ç—î–≤–æ
gen = read_large_file_good(large_n)
print(f"‚úÖ –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä —Å—Ç–≤–æ—Ä–µ–Ω–æ –º–∏—Ç—Ç—î–≤–æ: {gen}")

# –û–±—Ä–æ–±–∫–∞ –ø–µ—Ä—à–∏—Ö 5 –µ–ª–µ–º–µ–Ω—Ç—ñ–≤
print("–ü–µ—Ä—à—ñ 5 –µ–ª–µ–º–µ–Ω—Ç—ñ–≤:")
for i, value in enumerate(gen):
    if i >= 5:
        break
    print(f"  {value}")


def process_data_stream(data_generator, batch_size: int = 100):
    """
    –û–±—Ä–æ–±–ª—è—î –¥–∞–Ω—ñ –±–∞—Ç—á–∞–º–∏ –∑ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞
    –¢–∏–ø–æ–≤–∏–π –ø–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è ML training
    """
    batch = []
    processed = 0
    
    for item in data_generator:
        batch.append(item)
        
        if len(batch) >= batch_size:
            # –û–±—Ä–æ–±–∫–∞ –±–∞—Ç—á—É
            batch_sum = sum(batch)
            processed += len(batch)
            print(f"  –û–±—Ä–æ–±–ª–µ–Ω–æ –±–∞—Ç—á: {len(batch)} –µ–ª–µ–º–µ–Ω—Ç—ñ–≤, —Å—É–º–∞: {batch_sum}")
            batch = []
    
    # –û–±—Ä–æ–±–∫–∞ –æ—Å—Ç–∞–Ω–Ω—å–æ–≥–æ –±–∞—Ç—á—É
    if batch:
        processed += len(batch)
        print(f"  –û—Å—Ç–∞–Ω–Ω—ñ–π –±–∞—Ç—á: {len(batch)} –µ–ª–µ–º–µ–Ω—Ç—ñ–≤")
    
    return processed


print("\n–û–±—Ä–æ–±–∫–∞ stream –¥–∞–Ω–∏—Ö:")
data_stream = read_large_file_good(350)
total = process_data_stream(data_stream, batch_size=100)
print(f"–í—Å—å–æ–≥–æ –æ–±—Ä–æ–±–ª–µ–Ω–æ: {total} –µ–ª–µ–º–µ–Ω—Ç—ñ–≤")


# ============================================================================
# 5. MATCH-CASE - PATTERN MATCHING (Python 3.10+)
# ============================================================================

print("\n" + "=" * 70)
print("5. MATCH-CASE - STRUCTURAL PATTERN MATCHING (Python 3.10+)")
print("=" * 70)

def route_data_by_type(data: dict) -> str:
    """
    –†–æ—É—Ç–∏–Ω–≥ –¥–∞–Ω–∏—Ö –ø–æ —Ç–∏–ø—É - —Å—É—á–∞—Å–Ω–∏–π —Å–ø–æ—Å—ñ–±
    –ó–∞–º—ñ–Ω—é—î —Å–∫–ª–∞–¥–Ω—ñ if-elif-else
    """
    match data:
        case {"type": "csv", "path": path}:
            return f"üìÑ –û–±—Ä–æ–±–∫–∞ CSV: {path}"
        
        case {"type": "json", "path": path, "encoding": enc}:
            return f"üìã –û–±—Ä–æ–±–∫–∞ JSON: {path} ({enc})"
        
        case {"type": "parquet", "path": path}:
            return f"üóÇÔ∏è  –û–±—Ä–æ–±–∫–∞ Parquet: {path}"
        
        case {"type": "api", "url": url, "method": method}:
            return f"üåê API –∑–∞–ø–∏—Ç: {method} {url}"
        
        case {"type": str(type_name)}:
            return f"‚ö†Ô∏è  –ù–µ–≤—ñ–¥–æ–º–∏–π —Ç–∏–ø: {type_name}"
        
        case _:
            return "‚ùå –ù–µ–≤–∞–ª—ñ–¥–Ω—ñ –¥–∞–Ω—ñ"


# –¢–µ—Å—Ç–∏
test_cases = [
    {"type": "csv", "path": "data/train.csv"},
    {"type": "json", "path": "config.json", "encoding": "utf-8"},
    {"type": "parquet", "path": "data/features.parquet"},
    {"type": "api", "url": "https://api.example.com/data", "method": "GET"},
    {"type": "unknown"},
    {"invalid": "data"}
]

print("–†–æ—É—Ç–∏–Ω–≥ —Ä—ñ–∑–Ω–∏—Ö —Ç–∏–ø—ñ–≤ –¥–∞–Ω–∏—Ö:")
for data in test_cases:
    result = route_data_by_type(data)
    print(f"  {result}")


def process_ml_result(result: dict) -> str:
    """
    –û–±—Ä–æ–±–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ ML –º–æ–¥–µ–ª—ñ –∑ pattern matching
    """
    match result:
        case {"success": True, "predictions": list(preds), "confidence": float(conf)} if conf > 0.9:
            return f"‚úÖ –í–∏—Å–æ–∫–æ—Ç–æ—á–Ω–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {len(preds)} –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω—å (confidence: {conf:.2%})"
        
        case {"success": True, "predictions": list(preds), "confidence": float(conf)} if conf > 0.7:
            return f"‚ö†Ô∏è  –°–µ—Ä–µ–¥–Ω—è —Ç–æ—á–Ω—ñ—Å—Ç—å: {len(preds)} –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω—å (confidence: {conf:.2%})"
        
        case {"success": True, "predictions": list(preds)}:
            return f"‚ö†Ô∏è  –ù–∏–∑—å–∫–∞ —Ç–æ—á–Ω—ñ—Å—Ç—å: {len(preds)} –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω—å"
        
        case {"success": False, "error": str(error)}:
            return f"‚ùå –ü–æ–º–∏–ª–∫–∞: {error}"
        
        case _:
            return "‚ùå –ù–µ–≤–∞–ª—ñ–¥–Ω–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç"


# –¢–µ—Å—Ç–∏
ml_results = [
    {"success": True, "predictions": [1, 0, 1], "confidence": 0.95},
    {"success": True, "predictions": [0, 0, 1], "confidence": 0.75},
    {"success": False, "error": "Model not found"},
]

print("\n–û–±—Ä–æ–±–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ ML:")
for result in ml_results:
    print(f"  {process_ml_result(result)}")


# ============================================================================
# 6. DATACLASSES - –°–¢–†–£–ö–¢–£–†–û–í–ê–ù–Ü –î–ê–ù–Ü (Python 3.7+)
# ============================================================================

print("\n" + "=" * 70)
print("6. DATACLASSES - –°–£–ß–ê–°–ù–Ü DATA STRUCTURES")
print("=" * 70)

@dataclass
class DatasetInfo:
    """
    –Ü–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –ø—Ä–æ –¥–∞—Ç–∞—Å–µ—Ç
    
    Dataclass –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ –≥–µ–Ω–µ—Ä—É—î:
    - __init__
    - __repr__
    - __eq__
    """
    name: str
    rows: int
    columns: int
    size_mb: float
    features: list[str]
    
    @property
    def density(self) -> float:
        """–ì—É—Å—Ç–∏–Ω–∞ –¥–∞–Ω–∏—Ö"""
        return self.rows * self.columns
    
    def summary(self) -> str:
        """–ö–æ—Ä–æ—Ç–∫–∏–π –æ–ø–∏—Å –¥–∞—Ç–∞—Å–µ—Ç—É"""
        return f"{self.name}: {self.rows:,} rows √ó {self.columns} cols = {self.density:,} cells ({self.size_mb:.1f} MB)"


# –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –µ–∫–∑–µ–º–ø–ª—è—Ä—É - —á–∏—Å—Ç–æ —Ç–∞ –∑—Ä–æ–∑—É–º—ñ–ª–æ
dataset = DatasetInfo(
    name="Customer Churn",
    rows=100_000,
    columns=25,
    size_mb=12.5,
    features=["age", "tenure", "monthly_charges", "churn"]
)

print(f"Dataset: {dataset}")
print(f"Summary: {dataset.summary()}")


@dataclass
class MLModelMetrics:
    """–ú–µ—Ç—Ä–∏–∫–∏ ML –º–æ–¥–µ–ª—ñ"""
    model_name: str
    accuracy: float
    precision: float
    recall: float
    f1_score: float
    training_time_sec: float
    
    @property
    def is_good_performance(self) -> bool:
        """–ß–∏ –º–æ–¥–µ–ª—å –º–∞—î —Ö–æ—Ä–æ—à—ñ –ø–æ–∫–∞–∑–Ω–∏–∫–∏"""
        return self.f1_score > 0.8 and self.accuracy > 0.85
    
    def compare_with(self, other: 'MLModelMetrics') -> str:
        """–ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –∑ —ñ–Ω—à–æ—é –º–æ–¥–µ–ª–ª—é"""
        if self.f1_score > other.f1_score:
            return f"‚úÖ {self.model_name} –∫—Ä–∞—â–∞ –∑–∞ {other.model_name}"
        else:
            return f"‚ùå {other.model_name} –∫—Ä–∞—â–∞ –∑–∞ {self.model_name}"


# –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –º–æ–¥–µ–ª–µ–π
model_a = MLModelMetrics("Random Forest", 0.92, 0.89, 0.91, 0.90, 125.5)
model_b = MLModelMetrics("XGBoost", 0.94, 0.92, 0.93, 0.925, 98.3)

print(f"\n–ú–æ–¥–µ–ª—å A: {model_a.model_name}")
print(f"  F1 Score: {model_a.f1_score:.3f}")
print(f"  Good performance: {model_a.is_good_performance}")

print(f"\n–ú–æ–¥–µ–ª—å B: {model_b.model_name}")
print(f"  F1 Score: {model_b.f1_score:.3f}")
print(f"  Good performance: {model_b.is_good_performance}")

print(f"\n–ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è: {model_a.compare_with(model_b)}")


# ============================================================================
# 7. –§–£–ù–ö–¶–Ü–á –í–ò–©–û–ì–û –ü–û–†–Ø–î–ö–£ - MAP, FILTER, REDUCE
# ============================================================================

print("\n" + "=" * 70)
print("7. –§–£–ù–ö–¶–Ü–á –í–ò–©–û–ì–û –ü–û–†–Ø–î–ö–£ - –§–£–ù–ö–¶–Ü–û–ù–ê–õ–¨–ù–ï –ü–†–û–ì–†–ê–ú–£–í–ê–ù–ù–Ø")
print("=" * 70)

# –î–∞–Ω—ñ –¥–ª—è –æ–±—Ä–æ–±–∫–∏
raw_data = [
    {"id": 1, "value": 100, "category": "A"},
    {"id": 2, "value": 250, "category": "B"},
    {"id": 3, "value": 150, "category": "A"},
    {"id": 4, "value": 300, "category": "C"},
    {"id": 5, "value": 200, "category": "B"},
]

# Map - —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü—ñ—è
print("MAP - —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü—ñ—è –¥–∞–Ω–∏—Ö:")
enriched = list(map(
    lambda x: {**x, "value_squared": x["value"] ** 2},
    raw_data
))
print(f"  –î–æ–¥–∞–Ω–æ value_squared:")
for item in enriched[:2]:
    print(f"    ID {item['id']}: {item['value']} ‚Üí {item['value_squared']}")

# Filter - —Ñ—ñ–ª—å—Ç—Ä–∞—Ü—ñ—è
print("\nFILTER - –≤—ñ–¥–±—ñ—Ä –¥–∞–Ω–∏—Ö:")
high_value = list(filter(
    lambda x: x["value"] > 150,
    raw_data
))
print(f"  –ó–∞–ø–∏—Å—ñ–≤ –∑ value > 150: {len(high_value)}")
for item in high_value:
    print(f"    ID {item['id']}: value={item['value']}")

# Combine - chain operations
print("\nCOMBINE - –ª–∞–Ω—Ü—é–≥ –æ–ø–µ—Ä–∞—Ü—ñ–π:")
result = list(
    map(
        lambda x: x["value"] * 1.1,  # –ó–±—ñ–ª—å—à–∏—Ç–∏ –Ω–∞ 10%
        filter(
            lambda x: x["category"] == "A",  # –¢—ñ–ª—å–∫–∏ –∫–∞—Ç–µ–≥–æ—Ä—ñ—è A
            raw_data
        )
    )
)
print(f"  Category A –∑—ñ –∑–±—ñ–ª—å—à–µ–Ω–Ω—è–º: {result}")


# ============================================================================
# 8. PARTIAL FUNCTIONS - –°–ü–ï–¶–Ü–ê–õ–Ü–ó–ê–¶–Ü–Ø –§–£–ù–ö–¶–Ü–ô
# ============================================================================

print("\n" + "=" * 70)
print("8. PARTIAL FUNCTIONS - –°–ü–ï–¶–Ü–ê–õ–Ü–ó–ê–¶–Ü–Ø")
print("=" * 70)

def calculate_discount(price: float, discount_pct: float, tax_pct: float) -> float:
    """–†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ —Ü—ñ–Ω–∏ –∑ –∑–Ω–∏–∂–∫–æ—é —Ç–∞ –ø–æ–¥–∞—Ç–∫–æ–º"""
    discounted = price * (1 - discount_pct / 100)
    final_price = discounted * (1 + tax_pct / 100)
    return final_price


# –°—Ç–≤–æ—Ä—é—î–º–æ —Å–ø–µ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω—ñ —Ñ—É–Ω–∫—Ü—ñ—ó
black_friday_price = partial(calculate_discount, discount_pct=30, tax_pct=20)
regular_price = partial(calculate_discount, discount_pct=0, tax_pct=20)
member_price = partial(calculate_discount, discount_pct=15, tax_pct=20)

# –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è
prices = [100, 250, 500]

print("–°–ø–µ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω—ñ —Ñ—É–Ω–∫—Ü—ñ—ó —Ü—ñ–Ω–æ—É—Ç–≤–æ—Ä–µ–Ω–Ω—è:")
for price in prices:
    print(f"\n  –ë–∞–∑–æ–≤–∞ —Ü—ñ–Ω–∞: ${price}")
    print(f"    Regular: ${regular_price(price):.2f}")
    print(f"    Member: ${member_price(price):.2f}")
    print(f"    Black Friday: ${black_friday_price(price):.2f}")


# ============================================================================
# 9. ERROR HANDLING PATTERNS
# ============================================================================

print("\n" + "=" * 70)
print("9. –ü–†–û–§–ï–°–Ü–ô–ù–ê –û–ë–†–û–ë–ö–ê –ü–û–ú–ò–õ–û–ö")
print("=" * 70)

class DataValidationError(Exception):
    """Custom exception –¥–ª—è –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó –¥–∞–Ω–∏—Ö"""
    pass


def validate_and_process(
    data: list[dict]
) -> tuple[list[dict], list[str]]:
    """
    –í–∞–ª—ñ–¥—É—î —Ç–∞ –æ–±—Ä–æ–±–ª—è—î –¥–∞–Ω—ñ –∑ proper error handling
    
    Returns:
        tuple: (valid_data, errors)
    """
    valid_data = []
    errors = []
    
    for i, record in enumerate(data):
        try:
            # –í–∞–ª—ñ–¥–∞—Ü—ñ—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏
            if "value" not in record:
                raise DataValidationError(f"Missing 'value' field")
            
            # –í–∞–ª—ñ–¥–∞—Ü—ñ—è —Ç–∏–ø—É
            if not isinstance(record["value"], (int, float)):
                raise DataValidationError(f"'value' must be numeric")
            
            # –í–∞–ª—ñ–¥–∞—Ü—ñ—è –¥—ñ–∞–ø–∞–∑–æ–Ω—É
            if record["value"] < 0:
                raise DataValidationError(f"'value' must be positive")
            
            # –í–∞–ª—ñ–¥–∞—Ü—ñ—è –ø—Ä–æ–π–¥–µ–Ω–∞
            valid_data.append(record)
            
        except DataValidationError as e:
            errors.append(f"Record {i}: {e}")
        except Exception as e:
            errors.append(f"Record {i}: Unexpected error - {e}")
    
    return valid_data, errors


# –¢–µ—Å—Ç –∑ —Ä—ñ–∑–Ω–∏–º–∏ –¥–∞–Ω–∏–º–∏
test_data = [
    {"id": 1, "value": 100},      # OK
    {"id": 2, "name": "test"},    # Missing value
    {"id": 3, "value": "abc"},    # Wrong type
    {"id": 4, "value": -50},      # Negative
    {"id": 5, "value": 200},      # OK
]

valid, errors = validate_and_process(test_data)

print(f"–í–∞–ª—ñ–¥–Ω—ñ –∑–∞–ø–∏—Å–∏: {len(valid)}")
print(f"–ü–æ–º–∏–ª–∫–∏: {len(errors)}")
if errors:
    print("\n–î–µ—Ç–∞–ª—ñ –ø–æ–º–∏–ª–æ–∫:")
    for error in errors:
        print(f"  ‚ùå {error}")


# ============================================================================
# 10. –ö–û–ú–ü–û–ó–ò–¶–Ü–Ø –§–£–ù–ö–¶–Ü–ô - PIPELINE PATTERN
# ============================================================================

print("\n" + "=" * 70)
print("10. PIPELINE PATTERN - –ö–û–ú–ü–û–ó–ò–¶–Ü–Ø –§–£–ù–ö–¶–Ü–ô")
print("=" * 70)

def compose(*functions):
    """
    –ö–æ–º–ø–æ–∑–∏—Ü—ñ—è —Ñ—É–Ω–∫—Ü—ñ–π - —Ñ—É–Ω–∫—Ü—ñ–æ–Ω–∞–ª—å–Ω–∏–π –ø—ñ–¥—Ö—ñ–¥ –¥–æ pipelines
    """
    def inner(arg):
        result = arg
        for func in functions:
            result = func(result)
        return result
    return inner


# –§—É–Ω–∫—Ü—ñ—ó –¥–ª—è pipeline
def extract_values(data: list[dict]) -> list[float]:
    """Extract: –≤–∏—Ç—è–≥—É—î–º–æ –∑–Ω–∞—á–µ–Ω–Ω—è"""
    return [item["value"] for item in data if "value" in item]


def transform_scale(values: list[float]) -> list[float]:
    """Transform: –Ω–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è [0, 1]"""
    if not values:
        return []
    min_val, max_val = min(values), max(values)
    if max_val == min_val:
        return [0.5] * len(values)
    return [(v - min_val) / (max_val - min_val) for v in values]


def load_statistics(values: list[float]) -> dict:
    """Load: –æ–±—á–∏—Å–ª—é—î–º–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É"""
    if not values:
        return {"error": "No data"}
    return {
        "count": len(values),
        "mean": statistics.mean(values),
        "median": statistics.median(values),
        "stdev": statistics.stdev(values) if len(values) > 1 else 0
    }


# –°—Ç–≤–æ—Ä—é—î–º–æ ETL pipeline
etl_pipeline = compose(
    extract_values,
    transform_scale,
    load_statistics
)

# –¢–µ—Å—Ç pipeline
input_data = [
    {"id": 1, "value": 100},
    {"id": 2, "value": 200},
    {"id": 3, "value": 150},
    {"id": 4, "value": 300},
]

result = etl_pipeline(input_data)
print("ETL Pipeline —Ä–µ–∑—É–ª—å—Ç–∞—Ç:")
for key, value in result.items():
    if isinstance(value, float):
        print(f"  {key}: {value:.4f}")
    else:
        print(f"  {key}: {value}")


# ============================================================================
# –ü–Ü–î–°–£–ú–û–ö
# ============================================================================

print("\n" + "=" * 70)
print("–ü–Ü–î–°–£–ú–û–ö: –°–£–ß–ê–°–ù–Ü –ü–ê–¢–¢–ï–†–ù–ò –§–£–ù–ö–¶–Ü–ô")
print("=" * 70)

summary = """
‚úÖ –î–ï–ö–û–†–ê–¢–û–†–ò:
   - @timing_decorator - –ø—Ä–æ—Ñ—ñ–ª—é–≤–∞–Ω–Ω—è
   - @lru_cache - –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è
   - @log_calls - debugging

‚úÖ –ì–ï–ù–ï–†–ê–¢–û–†–ò:
   - yield –¥–ª—è –≤–µ–ª–∏–∫–∏—Ö –¥–∞–Ω–∏—Ö
   - –û–±—Ä–æ–±–∫–∞ stream –¥–∞–Ω–∏—Ö
   - –ë–∞—Ç—á processing

‚úÖ MATCH-CASE (Python 3.10+):
   - Pattern matching
   - Data routing
   - –ß–∏—Å—Ç—ñ—à–µ –∑–∞ if-elif-else

‚úÖ DATACLASSES:
   - –°—Ç—Ä—É–∫—Ç—É—Ä–æ–≤–∞–Ω—ñ –¥–∞–Ω—ñ
   - Auto-generated methods
   - Type hints

‚úÖ –§–£–ù–ö–¶–Ü–û–ù–ê–õ–¨–ù–ï –ü–†–û–ì–†–ê–ú–£–í–ê–ù–ù–Ø:
   - map, filter, reduce
   - Partial functions
   - Function composition

‚úÖ ERROR HANDLING:
   - Custom exceptions
   - Proper error messages
   - Validation patterns

‚úÖ PIPELINE PATTERN:
   - Function composition
   - ETL workflows
   - –ß–∏—Å—Ç–∏–π —Ç–∞ —á–∏—Ç–∞–±–µ–ª—å–Ω–∏–π –∫–æ–¥

üéØ –î–õ–Ø DATA SCIENCE/ENGINEERING:
   - –û–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è —á–µ—Ä–µ–∑ caching
   - Stream processing –¥–ª—è –≤–µ–ª–∏–∫–∏—Ö –¥–∞–Ω–∏—Ö
   - –ü—Ä–æ—Ñ–µ—Å—ñ–π–Ω–∞ –æ–±—Ä–æ–±–∫–∞ –ø–æ–º–∏–ª–æ–∫
   - –î–µ–∫–æ—Ä–∞—Ç–æ—Ä–∏ –¥–ª—è –º–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥—É
   - Dataclasses –¥–ª—è —Å—Ç—Ä—É–∫—Ç—É—Ä –¥–∞–Ω–∏—Ö
"""

print(summary)

print("\n‚ú® –¢–µ–ø–µ—Ä –≤–∏ –∑–Ω–∞—î—Ç–µ advanced –ø–∞—Ç—Ç–µ—Ä–Ω–∏ Python! ‚ú®\n")

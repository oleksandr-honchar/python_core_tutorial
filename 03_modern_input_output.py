"""
–ú–æ–¥—É–ª—å 2.1: –°—É—á–∞—Å–Ω–∏–π Input/Output —Ç–∞ —Ä–æ–±–æ—Ç–∞ –∑ –¥–∞–Ω–∏–º–∏
=====================================================

–ü—Ä–∏–∫–ª–∞–¥–Ω—ñ –ø—Ä–∏–∫–ª–∞–¥–∏ –¥–ª—è Data Science/Engineering
Python 3.10+ features
"""

from pathlib import Path
from datetime import datetime
import json

# ============================================================================
# 1. –°–£–ß–ê–°–ù–Ü F-STRINGS –¢–ê DEBUGGING
# ============================================================================

print("=" * 70)
print("1. –°–£–ß–ê–°–ù–Ü F-STRINGS (Python 3.8+)")
print("=" * 70)

# F-strings –∑ = –¥–ª—è debugging (Python 3.8+)
# –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ –ø–æ–∫–∞–∑—É—î –∑–º—ñ–Ω–Ω—É —Ç–∞ —ó—ó –∑–Ω–∞—á–µ–Ω–Ω—è
user_id = 12345
username = "data_scientist"
records_processed = 1_500_000  # Underscore –¥–ª—è —á–∏—Ç–∞–±–µ–ª—å–Ω–æ—Å—Ç—ñ

print(f"{user_id=}")  # user_id=12345
print(f"{username=}")  # username='data_scientist'
print(f"{records_processed=}")  # records_processed=1500000

# –§–æ—Ä–º–∞—Ç—É–≤–∞–Ω–Ω—è –≤ debugging mode
price = 1234.56789
print(f"{price=:.2f}")  # price=1234.57

# –í–∏—Ä–∞–∑–∏ –≤ f-strings –∑ =
data_size_mb = 2048
print(f"{data_size_mb / 1024=:.2f}")  # data_size_mb / 1024=2.00

# –ë–∞–≥–∞—Ç–æ—Ä—è–¥–∫–æ–≤—ñ f-strings –¥–ª—è –∑–≤—ñ—Ç—ñ–≤
model_name = "Random Forest"
accuracy = 0.9543
training_time = 125.7

report = f"""
Model Performance Report
{'=' * 40}
Model: {model_name}
Accuracy: {accuracy:.2%}
Training Time: {training_time:.1f}s
Timestamp: {datetime.now():%Y-%m-%d %H:%M:%S}
"""
print(report)


# ============================================================================
# 2. –†–û–ë–û–¢–ê –ó –†–ï–ê–õ–¨–ù–ò–ú–ò –î–ê–ù–ò–ú–ò - CSV PARSING
# ============================================================================

print("\n" + "=" * 70)
print("2. –û–ë–†–û–ë–ö–ê –î–ê–ù–ò–• –ó INPUT")
print("=" * 70)

def parse_csv_row(row: str) -> dict:
    """
    –ü–∞—Ä—Å–∏—Ç—å —Ä—è–¥–æ–∫ CSV –≤ —Å–ª–æ–≤–Ω–∏–∫
    
    Args:
        row: –†—è–¥–æ–∫ —Ñ–æ—Ä–º–∞—Ç—É "name,age,city,salary"
    
    Returns:
        dict: –°—Ç—Ä—É–∫—Ç—É—Ä–æ–≤–∞–Ω—ñ –¥–∞–Ω—ñ
    
    Example:
        >>> parse_csv_row("John,30,Kyiv,50000")
        {'name': 'John', 'age': 30, 'city': 'Kyiv', 'salary': 50000.0}
    """
    parts = row.strip().split(',')
    
    return {
        'name': parts[0],
        'age': int(parts[1]),
        'city': parts[2],
        'salary': float(parts[3])
    }

# –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü—ñ—è
sample_data = "Alice,28,Lviv,45000"
parsed = parse_csv_row(sample_data)
print(f"–í—Ö—ñ–¥–Ω—ñ –¥–∞–Ω—ñ: {sample_data}")
print(f"–†–æ–∑–ø–∞—Ä—Å–µ–Ω—ñ: {parsed}")
print(f"–¢–∏–ø: {type(parsed)}")


# ============================================================================
# 3. DATA VALIDATION - –ü–†–ò–ö–õ–ê–î–ù–ò–ô –ü–†–ò–ö–õ–ê–î
# ============================================================================

print("\n" + "=" * 70)
print("3. –í–ê–õ–Ü–î–ê–¶–Ü–Ø –î–ê–ù–ò–•")
print("=" * 70)

def validate_age(age: int | str) -> tuple[bool, int | None, str]:
    """
    –í–∞–ª—ñ–¥—É—î –≤—ñ–∫ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞
    
    Args:
        age: –í—ñ–∫ —è–∫ —á–∏—Å–ª–æ –∞–±–æ —Ä—è–¥–æ–∫
    
    Returns:
        tuple: (–≤–∞–ª—ñ–¥–Ω—ñ—Å—Ç—å, –∑–Ω–∞—á–µ–Ω–Ω—è, –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è)
        
    Note:
        –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î | –¥–ª—è union types (Python 3.10+)
    """
    try:
        age_int = int(age)
        
        if age_int < 0:
            return False, None, "–í—ñ–∫ –Ω–µ –º–æ–∂–µ –±—É—Ç–∏ –≤—ñ–¥'—î–º–Ω–∏–º"
        elif age_int > 150:
            return False, None, "–í—ñ–∫ –∑–∞–Ω–∞–¥—Ç–æ –≤–µ–ª–∏–∫–∏–π"
        elif age_int < 18:
            return False, age_int, "–ü–æ—Ç—Ä—ñ–±–Ω–æ –±—É—Ç–∏ 18+"
        else:
            return True, age_int, "–í–∞–ª—ñ–¥–Ω–∏–π –≤—ñ–∫"
            
    except ValueError:
        return False, None, "–í—ñ–∫ –ø–æ–≤–∏–Ω–µ–Ω –±—É—Ç–∏ —á–∏—Å–ª–æ–º"


# –¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è
test_ages = ["25", "150", "-5", "abc", "17"]

for age in test_ages:
    is_valid, value, message = validate_age(age)
    status = "‚úÖ" if is_valid else "‚ùå"
    print(f"{status} –í—ñ–∫ '{age}': {message} (–∑–Ω–∞—á–µ–Ω–Ω—è: {value})")


# ============================================================================
# 4. –°–¢–†–£–ö–¢–£–†–û–í–ê–ù–Ü –î–ê–ù–Ü - JSON –û–ü–ï–†–ê–¶–Ü–á
# ============================================================================

print("\n" + "=" * 70)
print("4. –†–û–ë–û–¢–ê –ó JSON (—Ç–∏–ø–æ–≤—ñ DS/DE –æ–ø–µ—Ä–∞—Ü—ñ—ó)")
print("=" * 70)

def create_data_record(
    user_id: int,
    features: list[float],
    label: str,
    metadata: dict | None = None
) -> dict:
    """
    –°—Ç–≤–æ—Ä—é—î –∑–∞–ø–∏—Å –¥–∞–Ω–∏—Ö –¥–ª—è ML pipeline
    
    Args:
        user_id: ID –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞
        features: Feature vector
        label: –¶—ñ–ª—å–æ–≤–∞ –∑–º—ñ–Ω–Ω–∞
        metadata: –î–æ–¥–∞—Ç–∫–æ–≤–∞ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è
    
    Returns:
        dict: –°—Ç—Ä—É–∫—Ç—É—Ä–æ–≤–∞–Ω–∏–π –∑–∞–ø–∏—Å
    """
    record = {
        'user_id': user_id,
        'features': features,
        'label': label,
        'timestamp': datetime.now().isoformat(),
        'version': '1.0'
    }
    
    if metadata:
        record['metadata'] = metadata
    
    return record


# –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –ø—Ä–∏–∫–ª–∞–¥—É
record = create_data_record(
    user_id=1001,
    features=[0.5, 0.8, 0.3, 0.9],
    label='positive',
    metadata={'source': 'api', 'confidence': 0.95}
)

print("–°—Ç–≤–æ—Ä–µ–Ω–∏–π –∑–∞–ø–∏—Å:")
print(json.dumps(record, indent=2, ensure_ascii=False))


# ============================================================================
# 5. ETL-LIKE –ü–†–ò–ö–õ–ê–î: –¢–†–ê–ù–°–§–û–†–ú–ê–¶–Ü–Ø –î–ê–ù–ò–•
# ============================================================================

print("\n" + "=" * 70)
print("5. –ü–†–û–°–¢–ò–ô ETL PIPELINE")
print("=" * 70)

def clean_salary_string(salary_str: str) -> float:
    """
    –û—á–∏—â—É—î —Ç–∞ –∫–æ–Ω–≤–µ—Ä—Ç—É—î –∑–∞—Ä–ø–ª–∞—Ç—É –∑ —Ä—ñ–∑–Ω–∏—Ö —Ñ–æ—Ä–º–∞—Ç—ñ–≤
    
    Examples:
        >>> clean_salary_string("$50,000")
        50000.0
        >>> clean_salary_string("45000 –≥—Ä–Ω")
        45000.0
        >>> clean_salary_string("1.5k USD")
        1500.0
    """
    # –í–∏–¥–∞–ª—è—î–º–æ –≤—Å–µ –∫—Ä—ñ–º —Ü–∏—Ñ—Ä, –∫—Ä–∞–ø–∫–∏ —Ç–∞ k
    cleaned = salary_str.replace(',', '').replace('$', '').replace('–≥—Ä–Ω', '').replace('USD', '').strip()
    
    # –û–±—Ä–æ–±–∫–∞ k (thousands)
    if 'k' in cleaned.lower():
        cleaned = cleaned.lower().replace('k', '')
        return float(cleaned) * 1000
    
    return float(cleaned)


def transform_salary_data(raw_salaries: list[str]) -> dict:
    """
    –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º—É—î —Å–∏—Ä—ñ –¥–∞–Ω—ñ –∑–∞—Ä–ø–ª–∞—Ç –≤ –∞–Ω–∞–ª—ñ—Ç–∏—á–Ω–∏–π —Ñ–æ—Ä–º–∞—Ç
    
    Returns:
        dict: –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∑–∞—Ä–ø–ª–∞—Ç–∞–º
    """
    cleaned_salaries = []
    
    for salary in raw_salaries:
        try:
            cleaned = clean_salary_string(salary)
            cleaned_salaries.append(cleaned)
        except ValueError as e:
            print(f"‚ö†Ô∏è  –ü–æ–º–∏–ª–∫–∞ –æ–±—Ä–æ–±–∫–∏ '{salary}': {e}")
            continue
    
    if not cleaned_salaries:
        return {'error': '–ù–µ–º–∞—î –≤–∞–ª—ñ–¥–Ω–∏—Ö –¥–∞–Ω–∏—Ö'}
    
    return {
        'count': len(cleaned_salaries),
        'min': min(cleaned_salaries),
        'max': max(cleaned_salaries),
        'avg': sum(cleaned_salaries) / len(cleaned_salaries),
        'total': sum(cleaned_salaries)
    }


# –¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è –∑ —Ä–µ–∞–ª—å–Ω–∏–º–∏ –¥–∞–Ω–∏–º–∏
raw_data = [
    "$50,000",
    "45000 –≥—Ä–Ω",
    "1.5k USD",
    "$75,000",
    "invalid",
    "60000"
]

stats = transform_salary_data(raw_data)
print("\n–í—Ö—ñ–¥–Ω—ñ –¥–∞–Ω—ñ:", raw_data)
print("\n–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
for key, value in stats.items():
    if isinstance(value, float):
        print(f"  {key}: ${value:,.2f}")
    else:
        print(f"  {key}: {value}")


# ============================================================================
# 6. PATHLIB - –°–£–ß–ê–°–ù–ê –†–û–ë–û–¢–ê –ó –§–ê–ô–õ–ê–ú–ò
# ============================================================================

print("\n" + "=" * 70)
print("6. PATHLIB - –°–£–ß–ê–°–ù–ò–ô –°–ü–û–°–Ü–ë (–∑–∞–º—ñ—Å—Ç—å os.path)")
print("=" * 70)

def get_data_file_info(filename: str) -> dict:
    """
    –û—Ç—Ä–∏–º—É—î —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ —Ñ–∞–π–ª –¥–∞–Ω–∏—Ö
    
    Args:
        filename: –ù–∞–∑–≤–∞ —Ñ–∞–π–ª—É
    
    Returns:
        dict: –Ü–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –ø—Ä–æ —Ñ–∞–π–ª
    """
    # Pathlib - —Å—É—á–∞—Å–Ω–∏–π —Å–ø–æ—Å—ñ–± (Python 3.4+)
    filepath = Path(filename)
    
    return {
        'filename': filepath.name,
        'extension': filepath.suffix,
        'stem': filepath.stem,  # –ù–∞–∑–≤–∞ –±–µ–∑ —Ä–æ–∑—à–∏—Ä–µ–Ω–Ω—è
        'parent': str(filepath.parent),
        'absolute': str(filepath.absolute()),
        'exists': filepath.exists(),
        'is_csv': filepath.suffix == '.csv',
        'is_json': filepath.suffix == '.json'
    }


# –ü—Ä–∏–∫–ª–∞–¥–∏ –∑ —Ä—ñ–∑–Ω–∏–º–∏ —Ñ–∞–π–ª–∞–º–∏
files = [
    'data/train.csv',
    'models/random_forest.pkl',
    'configs/settings.json'
]

for file in files:
    info = get_data_file_info(file)
    print(f"\nüìÅ {info['filename']}:")
    print(f"   –¢–∏–ø: {info['extension']}")
    print(f"   CSV: {info['is_csv']}, JSON: {info['is_json']}")


# ============================================================================
# 7. WALRUS OPERATOR - –°–£–ß–ê–°–ù–ò–ô PYTHON (3.8+)
# ============================================================================

print("\n" + "=" * 70)
print("7. WALRUS OPERATOR := (Python 3.8+)")
print("=" * 70)

def process_data_batch(data: list[int], threshold: int = 100) -> dict:
    """
    –û–±—Ä–æ–±–ª—è—î batch –¥–∞–Ω–∏—Ö –∑ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è–º walrus operator
    
    Walrus operator (:=) –¥–æ–∑–≤–æ–ª—è—î –ø—Ä–∏—Å–≤–æ—î–Ω–Ω—è –≤ –≤–∏—Ä–∞–∑–∞—Ö
    """
    results = []
    
    # –°—Ç–∞—Ä–∏–π —Å–ø–æ—Å—ñ–±:
    # filtered_data = [x for x in data if x > threshold]
    # if len(filtered_data) > 0:
    #     results = filtered_data
    
    # –ù–æ–≤–∏–π —Å–ø–æ—Å—ñ–± –∑ walrus:
    if (n := len([x for x in data if x > threshold])) > 0:
        print(f"‚úÖ –ó–Ω–∞–π–¥–µ–Ω–æ {n} –∑–∞–ø–∏—Å—ñ–≤ > {threshold}")
        results = [x for x in data if x > threshold]
    else:
        print(f"‚ùå –ù–µ–º–∞—î –∑–∞–ø–∏—Å—ñ–≤ > {threshold}")
    
    # Walrus –≤ list comprehension
    return {
        'total': len(data),
        'mean': (total := sum(data)) / len(data),  # Walrus!
        'sum': total,  # –ú–æ–∂–µ–º–æ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞—Ç–∏ –∑–Ω–æ–≤—É
        'filtered': len(results)
    }


# –¢–µ—Å—Ç
sample_data = [50, 150, 200, 30, 175, 80, 250]
result = process_data_batch(sample_data, threshold=100)
print(f"\n–†–µ–∑—É–ª—å—Ç–∞—Ç–∏: {result}")


# ============================================================================
# 8. TYPE HINTS - –°–£–ß–ê–°–ù–ê –ü–†–ê–ö–¢–ò–ö–ê
# ============================================================================

print("\n" + "=" * 70)
print("8. TYPE HINTS (Python 3.5+ / 3.10+ –¥–ª—è unions)")
print("=" * 70)

def calculate_metrics(
    predictions: list[int | float],
    actuals: list[int | float]
) -> dict[str, float]:
    """
    –û–±—á–∏—Å–ª—é—î –º–µ—Ç—Ä–∏–∫–∏ –º–æ–¥–µ–ª—ñ
    
    Args:
        predictions: –ü–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ
        actuals: –†–µ–∞–ª—å–Ω—ñ –∑–Ω–∞—á–µ–Ω–Ω—è
    
    Returns:
        –°–ª–æ–≤–Ω–∏–∫ –∑ –º–µ—Ç—Ä–∏–∫–∞–º–∏
        
    Note:
        - list[int | float] - Python 3.10+ —Å–∏–Ω—Ç–∞–∫—Å–∏—Å
        - –ó–∞–º—ñ—Å—Ç—å Union[int, float] –∑ typing
    """
    if len(predictions) != len(actuals):
        raise ValueError("–†—ñ–∑–Ω–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –µ–ª–µ–º–µ–Ω—Ç—ñ–≤")
    
    # Mean Absolute Error
    mae = sum(abs(p - a) for p, a in zip(predictions, actuals)) / len(predictions)
    
    # Mean Squared Error
    mse = sum((p - a) ** 2 for p, a in zip(predictions, actuals)) / len(predictions)
    
    # R¬≤ Score (simplified)
    mean_actual = sum(actuals) / len(actuals)
    ss_tot = sum((a - mean_actual) ** 2 for a in actuals)
    ss_res = sum((a - p) ** 2 for a, p in zip(actuals, predictions))
    r2 = 1 - (ss_res / ss_tot) if ss_tot != 0 else 0.0
    
    return {
        'mae': mae,
        'mse': mse,
        'rmse': mse ** 0.5,
        'r2': r2
    }


# –¢–µ—Å—Ç
y_pred = [100, 150, 200, 250]
y_true = [110, 145, 210, 240]

metrics = calculate_metrics(y_pred, y_true)
print("\n–ú–µ—Ç—Ä–∏–∫–∏ –º–æ–¥–µ–ª—ñ:")
for metric, value in metrics.items():
    print(f"  {metric.upper()}: {value:.4f}")


# ============================================================================
# 9. –ü–†–ê–ö–¢–ò–ß–ù–ò–ô –ü–†–ò–ö–õ–ê–î: DATA QUALITY CHECK
# ============================================================================

print("\n" + "=" * 70)
print("9. DATA QUALITY CHECKER")
print("=" * 70)

def check_data_quality(data: dict[str, list]) -> dict:
    """
    –ü–µ—Ä–µ–≤—ñ—Ä—è—î —è–∫—ñ—Å—Ç—å –¥–∞—Ç–∞—Å–µ—Ç—É
    
    Args:
        data: –°–ª–æ–≤–Ω–∏–∫ –∑ –∫–æ–ª–æ–Ω–∫–∞–º–∏ —Ç–∞ —ó—Ö –∑–Ω–∞—á–µ–Ω–Ω—è–º–∏
    
    Returns:
        –ó–≤—ñ—Ç –ø—Ä–æ —è–∫—ñ—Å—Ç—å –¥–∞–Ω–∏—Ö
    """
    report = {
        'total_columns': len(data),
        'columns': {}
    }
    
    for column_name, values in data.items():
        # –ü—ñ–¥—Ä–∞—Ö—É–Ω–æ–∫ missing values
        none_count = values.count(None)
        empty_count = sum(1 for v in values if v == '')
        missing_count = none_count + empty_count
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        report['columns'][column_name] = {
            'total': len(values),
            'missing': missing_count,
            'missing_pct': (missing_count / len(values) * 100) if values else 0,
            'filled': len(values) - missing_count,
            'unique': len(set(v for v in values if v not in [None, '']))
        }
    
    return report


# –ü—Ä–∏–∫–ª–∞–¥ –∑ —Ä–µ–∞–ª—å–Ω–∏–º–∏ –¥–∞–Ω–∏–º–∏
dataset = {
    'user_id': [1, 2, 3, 4, 5],
    'age': [25, None, 30, 28, None],
    'city': ['Kyiv', 'Lviv', '', 'Kharkiv', 'Odesa'],
    'salary': [50000, 45000, None, 60000, 55000]
}

quality_report = check_data_quality(dataset)

print("\nüìä Data Quality Report:")
print(f"–ó–∞–≥–∞–ª—å–Ω–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –∫–æ–ª–æ–Ω–æ–∫: {quality_report['total_columns']}")
print("\n–î–µ—Ç–∞–ª—ñ –ø–æ –∫–æ–ª–æ–Ω–∫–∞—Ö:")

for col, stats in quality_report['columns'].items():
    print(f"\n  {col}:")
    print(f"    –ó–∞–ø–æ–≤–Ω–µ–Ω–æ: {stats['filled']}/{stats['total']}")
    print(f"    –í—ñ–¥—Å—É—Ç–Ω—ñ: {stats['missing']} ({stats['missing_pct']:.1f}%)")
    print(f"    –£–Ω—ñ–∫–∞–ª—å–Ω—ñ: {stats['unique']}")


# ============================================================================
# 10. LOGGING BASICS - –ü–†–û–§–ï–°–Ü–ô–ù–ò–ô –ü–Ü–î–•–Ü–î
# ============================================================================

print("\n" + "=" * 70)
print("10. –õ–û–ì–£–í–ê–ù–ù–Ø –ó–ê–ú–Ü–°–¢–¨ PRINT (–ø—Ä–æ—Ñ–µ—Å—ñ–π–Ω–∏–π –ø—ñ–¥—Ö—ñ–¥)")
print("=" * 70)

import logging

# –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –ª–æ–≥—É–≤–∞–Ω–Ω—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)

logger = logging.getLogger(__name__)

def process_data_with_logging(data: list[int]) -> dict:
    """
    –û–±—Ä–æ–±–ª—è—î –¥–∞–Ω—ñ –∑ –ø—Ä–æ—Ñ–µ—Å—ñ–π–Ω–∏–º –ª–æ–≥—É–≤–∞–Ω–Ω—è–º
    
    –ó–∞–º—ñ—Å—Ç—å print() –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ logging –¥–ª—è production code
    """
    logger.info(f"–ü–æ—á–∞—Ç–æ–∫ –æ–±—Ä–æ–±–∫–∏ {len(data)} –∑–∞–ø–∏—Å—ñ–≤")
    
    # –í–∞–ª—ñ–¥–∞—Ü—ñ—è
    if not data:
        logger.warning("–û—Ç—Ä–∏–º–∞–Ω–æ –ø—É—Å—Ç–∏–π —Å–ø–∏—Å–æ–∫")
        return {'error': 'Empty data'}
    
    # –û–±—Ä–æ–±–∫–∞
    try:
        result = {
            'count': len(data),
            'sum': sum(data),
            'avg': sum(data) / len(data)
        }
        logger.info(f"–û–±—Ä–æ–±–ª–µ–Ω–æ —É—Å–ø—ñ—à–Ω–æ. –°–µ—Ä–µ–¥–Ω—î: {result['avg']:.2f}")
        return result
        
    except Exception as e:
        logger.error(f"–ü–æ–º–∏–ª–∫–∞ –æ–±—Ä–æ–±–∫–∏: {e}")
        raise


# –¢–µ—Å—Ç
try:
    result = process_data_with_logging([10, 20, 30, 40, 50])
    print(f"\n–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
except Exception as e:
    print(f"–ü–æ–º–∏–ª–∫–∞: {e}")


# ============================================================================
# –ü–Ü–î–°–£–ú–û–ö
# ============================================================================

print("\n" + "=" * 70)
print("–ü–Ü–î–°–£–ú–û–ö: –°–£–ß–ê–°–ù–Ü –ü–†–ê–ö–¢–ò–ö–ò PYTHON")
print("=" * 70)

summary = """
‚úÖ F-strings –∑ = –¥–ª—è debugging:
   print(f"{variable=}")

‚úÖ Type hints (Python 3.10+):
   def func(x: int | float) -> dict[str, float]

‚úÖ Walrus operator :=
   if (n := len(data)) > 10:

‚úÖ Pathlib –∑–∞–º—ñ—Å—Ç—å os.path:
   path = Path("data.csv")

‚úÖ Logging –∑–∞–º—ñ—Å—Ç—å print –¥–ª—è production:
   logger.info("Processing data...")

‚úÖ Data validation patterns:
   - Return tuple (is_valid, value, message)
   - Early returns –¥–ª—è –ø–æ–º–∏–ª–æ–∫

‚úÖ JSON –¥–ª—è —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–≤–∞–Ω–∏—Ö –¥–∞–Ω–∏—Ö:
   - API responses
   - –ö–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó
   - ML pipelines

‚úÖ Docstrings –∑ —Ç–∏–ø–∞–º–∏:
   - Args, Returns, Examples
   - Google/NumPy style

üéØ –î–ª—è Data Science/Engineering:
   - –í–∞–ª—ñ–¥–∞—Ü—ñ—è –¥–∞–Ω–∏—Ö
   - ETL patterns
   - Quality checks
   - Metrics calculation
   - Professional logging
"""

print(summary)

print("\n‚ú® –¢–µ–ø–µ—Ä –≤–∏ –∑–Ω–∞—î—Ç–µ —Å—É—á–∞—Å–Ω—ñ –ø—Ä–∞–∫—Ç–∏–∫–∏ Python! ‚ú®\n")
